## ETL, EL, ELT

### **ETL**

**Extract(추출) + Transform(변환) + Load(로드)**

![image](https://user-images.githubusercontent.com/108508730/233115227-26f7f3ba-6683-40c1-ac4a-8aafd12a1f4d.png)

위 그림의 데이터 파이프라인은 원시 데이터(스트리밍 데이터 or 배치 파일)에서 필요한 만큼 추출하고 변환해 필요한 정리나 집계 수행 후 빅쿼리에 로드함

빔(Beam)이나 스파크를 사용하지 않고 빅쿼리 하나로도 ETL 파이프라인 구축 가능

- GCS에 저장된 CSV 파일에 빅쿼리 SQL 실행 가능(= 통합 쿼리) → 통합 쿼리를 사용해서 데이터 추출하고, 변환한 다음 그 결과를 빅쿼리 테이블로 저장

### **EL**

**Extract(추출) + Load(로드)**

변환이 필요 없다면 csv, json 같은 데이터에 빅쿼리가 직접 접근하여 쿼리 실행 가능(EL 워크플로우)

- BUT 빅쿼리는 자체적인 스토리지 엔진을 가지고 있으므로 데이터를 빅쿼리 내부에 저장하는 것이 쿼리 성능에 가장 효율적
- 게다가 데이터를 데이터 웨어하우스(빅쿼리)로 로드하면 빅쿼리에서 제공하는 다양한 기능(자동 스케일링, 백업, 보안 등)들을 이용 가능

EL 설계 후 변환이 필요한 경우에만 ETL로 이동하는 것이 좋음

- 이때 가능하면 데이터 변환을 SQL로 수행하고 빅쿼리 내에 전체 ETL 파이프라인을 유지하는 것이 좋음
    - 빅쿼리 내에서 SQL을 사용하여 데이터를 처리하면 빅쿼리의 데이터 압축, 컬럼 스토리지, 분산 처리 등의 기술을 이용해서 빠르고 효율적인 대규모 데이터 처리가 가능
    - 데이터 이동을 최소화 할 수 있음
- SQL만으로 구현이 어렵거나 파이프라인에 데이터를 빅쿼리로 스트리밍해야 한다면 아파치 빔 파이프라인을 만들어 클라우드 데이터 플로우를 사용하는 서버리스 방식으로 실행
    - 빔 / 데이터플로우는 프로그래밍 코드이므로 이것으로 ETL 파이프라인을 구현하면 CI 및 단위 테스트 시스템과 통합이 잘 되는 장점이 있음

### ELT

**Extract(추출) + Load(로드) + Transform(변환)**

원시 데이터를 그대로 추출해 로드한 다음 빅쿼리 View로 해당 데이터를 즉시 변환하는 방법

→ 원시 데이터의 스키마가 유동적인 경우, 데이터를 사용하기위해 어떤 종류의 변환이 필요한 지 아직 모를 경우 사용

### 정리

![image](https://user-images.githubusercontent.com/108508730/233115308-fe0eaecd-8322-451f-8845-5f4953f8be29.png)
